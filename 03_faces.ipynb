{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GSuleh/Biometrics-Facial_Recognition_Lab_2/blob/main/03_faces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Face** Recognition\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Simple implementation of face recognition leveraging [ArcFace](https://openaccess.thecvf.com/content_CVPR_2019/papers/Deng_ArcFace_Additive_Angular_Margin_Loss_for_Deep_Face_Recognition_CVPR_2019_paper.pdf).  \n",
        "\n",
        "Language: Python 3  \n",
        "\n",
        "Needed libraries:\n",
        "* NumPy (https://numpy.org/)\n",
        "* matplotlib (https://matplotlib.org/)\n",
        "* OpenCV (https://opencv.org/)\n",
        "* ArcFace implementation (https://github.com/mobilesec/arcface-tensorflowlite), installed through PyPI (https://pypi.org/project/pip/).\n"
      ],
      "metadata": {
        "id": "W2h79Hrpn2yV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Needed libraries and files"
      ],
      "metadata": {
        "id": "ED_n3gjLCnzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download of pre-trained face detection models\n",
        "!pip install gdown\n",
        "!gdown 1SLPTyomKCNF7j98Vf0L00fWZy_uiKsHn\n",
        "!gdown 1r22yYX5sqor0vgqXoJcfdRkApji8w-7G\n",
        "!gdown 1vXBmymfKmJp1B8hjyjxJKUWfK686ptXX"
      ],
      "metadata": {
        "id": "C7ILncDjboKB",
        "outputId": "d7aad14c-a3b9-45a1-9416-ff9221b7920f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.15.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.7.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1SLPTyomKCNF7j98Vf0L00fWZy_uiKsHn\n",
            "From (redirected): https://drive.google.com/uc?id=1SLPTyomKCNF7j98Vf0L00fWZy_uiKsHn&confirm=t&uuid=b7dbb586-0bda-44fd-9a68-2acdf9ff1e13\n",
            "To: /content/violajones_haarcascade_eye.xml\n",
            "100% 341k/341k [00:00<00:00, 107MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1r22yYX5sqor0vgqXoJcfdRkApji8w-7G\n",
            "From (redirected): https://drive.google.com/uc?id=1r22yYX5sqor0vgqXoJcfdRkApji8w-7G&confirm=t&uuid=6ca7220f-2dd5-4c48-99ab-39897784722b\n",
            "To: /content/violajones_haarcascade_frontalface_default.xml\n",
            "100% 930k/930k [00:00<00:00, 113MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1vXBmymfKmJp1B8hjyjxJKUWfK686ptXX\n",
            "From (redirected): https://drive.google.com/uc?id=1vXBmymfKmJp1B8hjyjxJKUWfK686ptXX&confirm=t&uuid=12cf4aa1-ed9d-4fa2-8a50-cec79efd3984\n",
            "To: /content/model.tflite\n",
            "100% 161M/161M [00:01<00:00, 109MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ArcFace instalation and auxiliary libraries\n",
        "# Reference: https://github.com/mobilesec/arcface-tensorflowlite\n",
        "!pip install arcface"
      ],
      "metadata": {
        "id": "bUw-J0qHnFXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# other imported libraries\n",
        "import numpy as np\n",
        "print('NumPy version', np.__version__)\n",
        "\n",
        "import matplotlib as plt\n",
        "print('Matplotlib version', plt.__version__)\n",
        "\n",
        "import cv2\n",
        "print('OpenCV version', cv2.__version__)"
      ],
      "metadata": {
        "id": "o06jf3svCq4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------\n",
        "## Face acquisition"
      ],
      "metadata": {
        "id": "MJkFzjVKCTRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auxiliary function\n",
        "* <code>_capture_png</code>: to open the webcam and capture a PNG file.\n"
      ],
      "metadata": {
        "id": "pV0epaDNFs7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "# javascript-based function to capture pictures from the webcam in PNG\n",
        "def _capture_png(filename):\n",
        "  js = Javascript('''\n",
        "    async function capture() {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture PNG';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "\n",
        "      return canvas.toDataURL('image/png');\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  data = eval_js('capture()')\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)"
      ],
      "metadata": {
        "id": "liVLCnlEFsCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests capturing PNG file from the webcam\n",
        "# webcam test\n",
        "image_filepath = '/content/capture.png'\n",
        "_capture_png(image_filepath)\n",
        "\n",
        "image = cv2.imread(image_filepath)\n",
        "plt.pyplot.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "plt.pyplot.show()"
      ],
      "metadata": {
        "id": "dG1OHgugG9BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main functions"
      ],
      "metadata": {
        "id": "WHTTAYzXGaEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Acquires an image that might contain a face from the given file path.\n",
        "# The image is acquired with three color channels (BGR).\n",
        "# Parameters\n",
        "# file_path: The path to the image file containing the face.\n",
        "# view: TRUE if loaded image must be shown, FALSE otherwise.\n",
        "def acquire_from_file(file_path, view=False):\n",
        "    # reads the image from the given file path\n",
        "    # and returns it\n",
        "    image = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # shows the read image, if it is the case\n",
        "    if view:\n",
        "        plt.pyplot.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "        plt.pyplot.title('Face acquisition')\n",
        "        plt.pyplot.show()\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "nh2RQv0VGj8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests the file-based face acquisition function\n",
        "image_filepath = '/content/capture.png'\n",
        "image = acquire_from_file(image_filepath, view=True)\n",
        "assert image.size > 0"
      ],
      "metadata": {
        "id": "1Pwc2mUTGzGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Acquires an image that might contain a face from the webcam.\n",
        "# The image is acquired with three color channels (BGR).\n",
        "# Parameters\n",
        "# image_filepath: The path to the image file that will store the captured PNG\n",
        "# view: TRUE if captured image must be shown, FALSE otherwise.\n",
        "def acquire_from_cam(image_filepath='/content/capture.png', view=False):\n",
        "  # webcam capture\n",
        "  _capture_png(image_filepath)\n",
        "\n",
        "  # acquisition from file\n",
        "  return acquire_from_file(image_filepath, view=view)"
      ],
      "metadata": {
        "id": "RHEmrE-UICqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests the webcam-based face acquisition function\n",
        "image = acquire_from_cam(view=True)\n",
        "assert image.size > 0"
      ],
      "metadata": {
        "id": "RJl1ncA-JSAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------\n",
        "## Face enhancement"
      ],
      "metadata": {
        "id": "AfmHRRVFJeoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auxiliary function\n",
        "* <code>_rotate_face</code>: to rotate the given face image keeping eyes at the same level."
      ],
      "metadata": {
        "id": "Yu_Ox6BGKdTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rotates the given <image> and reference face rectangle <face_rect> CCW,\n",
        "# obeying the given <rad_angle>.\n",
        "# returns the rotated image and new face rectangle (x, y, w, h).\n",
        "def _rotate_face(image, face_rect, rad_angle):\n",
        "    # rotation matrix\n",
        "    sine = np.sin(rad_angle)\n",
        "    cosine = np.cos(rad_angle)\n",
        "\n",
        "    rot_mat = np.zeros((3, 3))\n",
        "    rot_mat[0, 0] = cosine\n",
        "    rot_mat[0, 1] = -sine\n",
        "    rot_mat[1, 0] = sine\n",
        "    rot_mat[1, 1] = cosine\n",
        "    rot_mat[2, 2] = 1.0\n",
        "\n",
        "    # rotates the image borders\n",
        "    rot_border = np.array([(0, 0), (0, image.shape[0]), (image.shape[1], 0), (image.shape[1], image.shape[0])])\n",
        "    rot_border = cv2.perspectiveTransform(np.float32([rot_border]), rot_mat)[0]\n",
        "    rot_w = int(round(np.max(rot_border[:, 0]) - np.min(rot_border[:, 0])))\n",
        "    rot_h = int(round(np.max(rot_border[:, 1]) - np.min(rot_border[:, 1])))\n",
        "\n",
        "    # translation added to the rotation matrix to compensate for negative points\n",
        "    rot_mat[0, 2] = rot_mat[0, 2] - np.min(rot_border[:, 0])\n",
        "    rot_mat[1, 2] = rot_mat[1, 2] - np.min(rot_border[:, 1])\n",
        "\n",
        "    # rotates the given image\n",
        "    rot_image = cv2.warpPerspective(image, rot_mat, (rot_w, rot_h))\n",
        "\n",
        "    # rotates the given face rectangle\n",
        "    x, y, w, h = face_rect\n",
        "    rot_face_rect = np.array([(x, y), (x + w, y), (x, y + h), (x + w, y + h)])\n",
        "    rot_face_rect = cv2.perspectiveTransform(np.float32([rot_face_rect]), rot_mat)[0]\n",
        "\n",
        "    # computes a new non-rotated face rectangle containing the rotated one\n",
        "    new_face_rect = np.min(rot_face_rect[:, 0]), np.min(rot_face_rect[:, 1]), np.max(\n",
        "        rot_face_rect[:, 0]), np.max(rot_face_rect[:, 1])\n",
        "\n",
        "    new_face_rect = int(round(new_face_rect[0])), int(round(new_face_rect[1])), int(\n",
        "        round(new_face_rect[2] - new_face_rect[0])), int(round(new_face_rect[3] - new_face_rect[1]))\n",
        "\n",
        "    # returns the rotated image and new face rectangle\n",
        "    return rot_image, new_face_rect"
      ],
      "metadata": {
        "id": "t145N80qKzvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests the image rotation\n",
        "# original toy-case image with synthetic face (white circle)\n",
        "# and detection (green rectangle)\n",
        "original_image = np.zeros((100, 100, 3), dtype=np.uint8)\n",
        "cv2.circle(original_image, (20, 50), 10, (255, 255, 255), -1)\n",
        "cv2.circle(original_image, (16, 48), 2, (0, 0, 0), -1)\n",
        "cv2.circle(original_image, (24, 48), 2, (0, 0, 0), -1)\n",
        "cv2.line(original_image, (16, 55), (24, 55), (0, 0, 0), 1)\n",
        "\n",
        "face_rect = 10, 40, 20, 20\n",
        "face_rect_p1 = face_rect[0:2]\n",
        "face_rect_p2 = (face_rect[0] + face_rect[2], face_rect[1] + face_rect[3])\n",
        "\n",
        "detection_image = original_image.copy()\n",
        "cv2.rectangle(detection_image, face_rect_p1, face_rect_p2, (0, 255, 0), 1)\n",
        "\n",
        "plt.pyplot.imshow(cv2.cvtColor(detection_image, cv2.COLOR_BGR2RGB))\n",
        "plt.pyplot.title('Original image and detection')\n",
        "plt.pyplot.show()\n",
        "\n",
        "# rotates the image by 90 degrees CCW\n",
        "rot_image, new_face_rect = _rotate_face(original_image, face_rect, np.pi / 2)\n",
        "new_face_rect_p1 = new_face_rect[0:2]\n",
        "new_face_rect_p2 = (new_face_rect[0] + new_face_rect[2],\n",
        "                    new_face_rect[1] + new_face_rect[3])\n",
        "\n",
        "detection_rot_image = rot_image.copy()\n",
        "cv2.rectangle(detection_rot_image, new_face_rect_p1, new_face_rect_p2,(0, 255, 0), 1)\n",
        "\n",
        "plt.pyplot.imshow(cv2.cvtColor(detection_rot_image, cv2.COLOR_BGR2RGB))\n",
        "plt.pyplot.title('Rotated image and detection (90 degrees CCW)')\n",
        "plt.pyplot.show()\n",
        "\n",
        "# rotates the image by 45 degrees CCW\n",
        "rot_image, new_face_rect = _rotate_face(original_image, face_rect, np.pi / 4)\n",
        "new_face_rect_p1 = new_face_rect[0:2]\n",
        "new_face_rect_p2 = (new_face_rect[0] + new_face_rect[2],\n",
        "                    new_face_rect[1] + new_face_rect[3])\n",
        "\n",
        "detection_rot_image = rot_image.copy()\n",
        "cv2.rectangle(detection_rot_image, new_face_rect_p1, new_face_rect_p2,(0, 255, 0), 1)\n",
        "\n",
        "plt.pyplot.imshow(cv2.cvtColor(detection_rot_image, cv2.COLOR_BGR2RGB))\n",
        "plt.pyplot.title('Rotated image and detection (45 degrees CCW)')\n",
        "plt.pyplot.show()"
      ],
      "metadata": {
        "id": "0kZrg9aILxg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main steps\n",
        "* <code>_01_preprocess</code>: to pre-process the given image, resizing and bringing it to grayscale.\n",
        "* <code>_02_detect_face</code>: to detect a face on the given image.\n",
        "* <code>_03_align_face</code>: to align the face so that both eyes are leveled.\n",
        "* <code>_04_extract_face</code>: to crop and normalize the colors of the detected face."
      ],
      "metadata": {
        "id": "LBYuvy0UZgyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesses the given <image> for further face detection.\n",
        "# Provide <view> as True if you want to see the result of computations.\n",
        "# Returns the preprocessed image.\n",
        "def _01_preprocess(image, image_width=640, view=False):\n",
        "    # makes the image grayscale, if it is still colored\n",
        "    if len(image.shape) > 2 and image.shape[2] > 1:  # more than one channel?\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # resizes the image to present a width of <image_width> pixels,\n",
        "    # keeping the original aspect ratio\n",
        "    aspect_ratio = float(image.shape[1]) / image.shape[0]\n",
        "    height = int(round(image_width / aspect_ratio))\n",
        "    image = cv2.resize(image, (image_width, height))\n",
        "\n",
        "    # shows the obtained image, if it is the case\n",
        "    if view:\n",
        "      plt.pyplot.imshow(image, cmap='gray')\n",
        "      plt.pyplot.title('Pre-processed image')\n",
        "      plt.pyplot.show()\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "ClrIEsqrYl2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests the pre-processing of a given image\n",
        "image = acquire_from_file('/content/capture.png', view=True)\n",
        "pp_image = _01_preprocess(image, view=True)"
      ],
      "metadata": {
        "id": "Epor2yhRaTDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detects the largest face over the given gray-scaled image.\n",
        "# Provide <view> as True if you want to see the result of computations.\n",
        "# Returns the rectangle (x, y, w, h) of the detected face.\n",
        "def _02_detect_face(gs_image,\n",
        "                    model_path='/content/violajones_haarcascade_frontalface_default.xml',\n",
        "                    view=False):\n",
        "    # detects faces on the given image with the Viola-Jones detector\n",
        "    vj_face_detector = cv2.CascadeClassifier(model_path)\n",
        "    face_boxes = vj_face_detector.detectMultiScale(gs_image)\n",
        "\n",
        "    # if there are no faces, returns None\n",
        "    if len(face_boxes) == 0:\n",
        "        return None\n",
        "\n",
        "    # else...\n",
        "    # takes the largest face among the detected ones\n",
        "    # TODO detecting more faces can be added here\n",
        "    x, y, w, h = 0, 0, 0, 0\n",
        "    size = 0\n",
        "    for face in face_boxes:\n",
        "        if face[2] * face[3] > size:\n",
        "            x, y, w, h = face\n",
        "            size = w * h\n",
        "\n",
        "    # show the obtained face, if it is the case\n",
        "    if view:\n",
        "        view_image = cv2.cvtColor(gs_image, cv2.COLOR_GRAY2BGR)\n",
        "        cv2.rectangle(view_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "        plt.pyplot.imshow(cv2.cvtColor(view_image, cv2.COLOR_BGR2RGB))\n",
        "        plt.pyplot.title('Detected face')\n",
        "        plt.pyplot.show()\n",
        "\n",
        "    return x, y, w, h"
      ],
      "metadata": {
        "id": "dNdCbQXWa41B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detecs a face on the given image\n",
        "face = _02_detect_face(pp_image, view=True)\n",
        "print('Detected face:', face)"
      ],
      "metadata": {
        "id": "ZQm6NX6Ldpfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms the given gray-scaled image <gs_image> according to the given\n",
        "# face position <face_rect>, making it up-face aligned with the horizontal line.\n",
        "# Provide <view> as True if you want to see the result of computations.\n",
        "# Returns the transformed image and new rectangle (x, y, w, h)\n",
        "# of the aligned face.\n",
        "def _03_align_face(gs_image, face_rect,\n",
        "                   model_path='/content/violajones_haarcascade_eye.xml',\n",
        "                   view=False):\n",
        "    # focus on the image region containing the face\n",
        "    x, y, w, h = face_rect\n",
        "    face_image = gs_image[y:y + h, x:x + w]\n",
        "\n",
        "    # detects eyes on the face with Viola-Jones detector\n",
        "    vj_eyes_detector = cv2.CascadeClassifier(model_path)\n",
        "    eye_boxes = vj_eyes_detector.detectMultiScale(face_image)\n",
        "\n",
        "    # if eyes were detected...\n",
        "    if len(eye_boxes) == 2:\n",
        "        # rotates the face in a way that eyes are aligned\n",
        "        # in the horizontal position\n",
        "        x1, y1, w1, h1, = eye_boxes[0]  # eye 1\n",
        "        x2, y2, w2, h2, = eye_boxes[1]  # eye 2\n",
        "\n",
        "        if x1 < x2:\n",
        "            xc1 = x1 + w1 / 2.0  # right eye, mirrored on the left\n",
        "            yc1 = y1 + h1 / 2.0\n",
        "\n",
        "            xc2 = x2 + w2 / 2.0  # left eye, mirrored on the right\n",
        "            yc2 = y2 + h2 / 2.0\n",
        "\n",
        "        else:\n",
        "            xc2 = x1 + w1 / 2.0  # left eye, mirrored on the right\n",
        "            yc2 = y1 + h1 / 2.0\n",
        "\n",
        "            xc1 = x2 + w2 / 2.0  # right eye, mirrored on the right\n",
        "            yc1 = y2 + h2 / 2.0\n",
        "\n",
        "        # angle between eyes\n",
        "        angle = np.arctan2(yc2 - yc1, xc2 - xc1)\n",
        "\n",
        "        # obtains the aligned image and new face rectangle\n",
        "        gs_image, face_rect = _rotate_face(gs_image, face_rect, -angle)\n",
        "\n",
        "    # shows the aligned face, if it is the case\n",
        "    if view:\n",
        "        x, y, w, h = face_rect\n",
        "        view_image = cv2.cvtColor(gs_image, cv2.COLOR_GRAY2BGR)\n",
        "        cv2.rectangle(view_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "        plt.pyplot.imshow(cv2.cvtColor(view_image, cv2.COLOR_BGR2RGB))\n",
        "        plt.pyplot.title('Aligned face')\n",
        "        plt.pyplot.show()\n",
        "\n",
        "    return gs_image, face_rect"
      ],
      "metadata": {
        "id": "Z4bA0b9NfE27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aligns the detected face\n",
        "al_image, al_face = _03_align_face(pp_image, face, view=True)\n",
        "print('Aligned face:', al_face)"
      ],
      "metadata": {
        "id": "wQDDaYSefzde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crops and normalizes the face contained in the given gray-scaled image\n",
        "# <gs_image>, following the provided face rectangle <face_rect>.\n",
        "# Provide <view> as True if you want to see the result of computations.\n",
        "# Returns the extracted face, ready for description (feature extraction).\n",
        "def _04_extract_face(gs_image, face_rect, face_size=256, view=False):\n",
        "    x, y, w, h = face_rect\n",
        "    cx = int(round(x + w / 2.0))\n",
        "    cy = int(round(y + h / 2.0))\n",
        "    r = int(round(max(w, h) / 2.0))\n",
        "\n",
        "    face_image = gs_image[\n",
        "                 max(0, cy - r):min(cy + r + 1, gs_image.shape[0]),\n",
        "                 max(0, cx - r):min(cx + r + 1, gs_image.shape[1])]  # squared face\n",
        "    if len(face_image) > 0:\n",
        "        face_image = cv2.resize(face_image, (face_size, face_size))  # face in normalized size\n",
        "        face_image = cv2.equalizeHist(face_image)  # color histogram normalization\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "    if view:\n",
        "      plt.pyplot.imshow(face_image, cmap='gray')\n",
        "      plt.pyplot.title('Extracted face')\n",
        "      plt.pyplot.show()\n",
        "\n",
        "    return face_image"
      ],
      "metadata": {
        "id": "zceO8nsjg--9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests the extraction of face\n",
        "face_image = _04_extract_face(al_image, al_face, view=True)"
      ],
      "metadata": {
        "id": "VmqIDAvQhkVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main function"
      ],
      "metadata": {
        "id": "W1tSxydyiqyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhances the given image, returning the normalized version of the largest\n",
        "# face depicted within it.\n",
        "# Provide <view> as True if you want to see the results of computations.\n",
        "# Returns the normalized face image, useful for description (feature extraction)\n",
        "# or None, if no face was detected.\n",
        "def enhance(image, view=False):\n",
        "    # pre-processes the given image\n",
        "    pp_image = _01_preprocess(image, view=view)\n",
        "\n",
        "    # detects a face in the given image\n",
        "    face_rect = _02_detect_face(pp_image, view=view)\n",
        "\n",
        "    if face_rect is not None:\n",
        "        # aligns the obtained face\n",
        "        aligned_image, aligned_face = _03_align_face(pp_image, face_rect, view=view)\n",
        "\n",
        "        # extracts and returns the detected face\n",
        "        return _04_extract_face(aligned_image, aligned_face, view=view)\n",
        "\n",
        "    # no face was found\n",
        "    return None"
      ],
      "metadata": {
        "id": "o-HyRFjwitcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests the enhancement function\n",
        "image = acquire_from_file('/content/capture.png', view=True)\n",
        "face_image = enhance(image, view=True)"
      ],
      "metadata": {
        "id": "ozY8dBkijNwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------\n",
        "## Face description"
      ],
      "metadata": {
        "id": "dhdbE-jaaSta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main function"
      ],
      "metadata": {
        "id": "p_AiY_ExvYi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from arcface import ArcFace\n",
        "\n",
        "# Describes the given normalized face image <norm_face> with ArcFace.\n",
        "# Returns the obtained feature vector.\n",
        "def describe(norm_face, arc_face_model='/content/model.tflite'):\n",
        "    face_descriptor = ArcFace.ArcFace(model_path=arc_face_model)\n",
        "    feature_vector = face_descriptor.calc_emb(norm_face)\n",
        "    return feature_vector"
      ],
      "metadata": {
        "id": "GNhYKvNAvX1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests the face description\n",
        "description = describe(face_image)\n",
        "print('Feature vector size:', description.shape)\n",
        "print('Feature vector:', description)"
      ],
      "metadata": {
        "id": "ixQN2diyvvSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------\n",
        "## Face matching"
      ],
      "metadata": {
        "id": "K10AH52Our1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main function"
      ],
      "metadata": {
        "id": "Vxu4MSyaW40j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from arcface import ArcFace\n",
        "\n",
        "# Matches the given feature vectors <description_1> and <description_2>.\n",
        "# Returns the distance between them, expressing how likely they are of\n",
        "# representing the same face.\n",
        "# The distance is a positive real number.\n",
        "def match(description_1, description_2, arc_face_model='/content/model.tflite'):\n",
        "    face_descriptor = ArcFace.ArcFace(model_path=arc_face_model)\n",
        "    distance = face_descriptor.get_distance_embeddings(description_1,\n",
        "                                                       description_2)\n",
        "    return distance"
      ],
      "metadata": {
        "id": "Ol1R6X_IwM9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tests the matching function\n",
        "# same face compared to itself (same capture)\n",
        "dist = match(description, description)\n",
        "print('Distance:' , dist)\n",
        "assert dist == 0\n"
      ],
      "metadata": {
        "id": "v08j2AloyAmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dynamicaly acquired faces\n",
        "image_1 = acquire_from_cam(view=True)\n",
        "image_2 = acquire_from_cam(view=True)\n",
        "\n",
        "face_1 = enhance(image_1, view=True)\n",
        "face_2 = enhance(image_2, view=True)\n",
        "\n",
        "description_1 = describe(face_1)\n",
        "description_2 = describe(face_2)\n",
        "dist = match(description_1, description_2)\n",
        "print('Distance:' , dist)"
      ],
      "metadata": {
        "id": "9zqv_WLjzVwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "________\n",
        "## Exercise\n",
        "\n",
        "Download the 16 images with faces below and study their distances according to ArcFace's description."
      ],
      "metadata": {
        "id": "pjP2P_Gzzm8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download of 16 images\n",
        "!gdown 1Y5rQb6HGgpxlnj6LNo6u_lUctr6dgGwA\n",
        "!gdown 1yVBf2s779yAS5cm22AC6IJ1fnU-zsMOZ\n",
        "!gdown 1UQJqcgJKYLKJWCfi6gFae_4npa95M-LS\n",
        "!gdown 1cAi4lCnsuXM2Lcd7gbhJZx_GoFusfN1i\n",
        "!gdown 1FizW_0tCc5ysbJyPr3_hXCZZOTxvXi3O\n",
        "!gdown 1a4pWT7423G3HLt8mDUtr79nYjR9EBOWO\n",
        "!gdown 1Zw2SGR8li3k7Oi3PPlAlUvUaRNLlQ2dc\n",
        "!gdown 1ULuUlNIdnN7hkSSJti7psFYH65VQVDGt\n",
        "!gdown 1hO82av0RUJO1ECK2scm6miAETjCg-OIs\n",
        "!gdown 1_Aca0L5QcioA6Uivss7KOHivQLN7uN_z\n",
        "!gdown 1VtFelqyqYSLl4MBIOj5c2ov00Auesjai\n",
        "!gdown 1sCxXJqtEu3SOtxX4JiPxvp4bYQ4Ppt6G\n",
        "!gdown 1nBLwFuUf8GHm5cgHojtCKjrBcKH4BDgR\n",
        "!gdown 12MI79nkO8IZfP9uW8pNsNgRkz4gEV19_\n",
        "!gdown 1HRZX8BaAimfZj0NV2bfR8FoSuddJQOZn\n",
        "!gdown 1XrqSXNKCPyruyhIGWvnHbZlhIik0okkC"
      ],
      "metadata": {
        "id": "Q867JC5z4XTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtained faces\n",
        "image_0101 = acquire_from_file('/content/0101.jpg', view=True)\n",
        "image_0102 = acquire_from_file('/content/0102.jpg', view=True)\n",
        "image_0201 = acquire_from_file('/content/0201.jpg', view=True)\n",
        "image_0202 = acquire_from_file('/content/0202.jpg', view=True)\n",
        "image_0301 = acquire_from_file('/content/0301.jpg', view=True)\n",
        "image_0302 = acquire_from_file('/content/0302.jpg', view=True)\n",
        "image_0401 = acquire_from_file('/content/0401.jpg', view=True)\n",
        "image_0402 = acquire_from_file('/content/0402.jpg', view=True)\n",
        "image_0501 = acquire_from_file('/content/0501.jpg', view=True)\n",
        "image_0502 = acquire_from_file('/content/0502.jpg', view=True)\n",
        "image_0601 = acquire_from_file('/content/0601.jpg', view=True)\n",
        "image_0602 = acquire_from_file('/content/0602.jpg', view=True)\n",
        "image_0701 = acquire_from_file('/content/0701.jpg', view=True)\n",
        "image_0702 = acquire_from_file('/content/0702.jpg', view=True)\n",
        "image_0801 = acquire_from_file('/content/0801.jpg', view=True)\n",
        "image_0802 = acquire_from_file('/content/0802.jpg', view=True)"
      ],
      "metadata": {
        "id": "BaazR6E-Djcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add your study here\n"
      ],
      "metadata": {
        "id": "WbadJsHUFQpg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}